import streamlit as st
import os
import sqlite3
from PIL import Image, ImageEnhance
import re
from datetime import datetime, date
import torch
import clip

# –ü—É—Ç–∏
etalon_folder = "–±–∞—Ç—á–∏–Ω–≥-—Ç–µ—Å—Ç/–°—Ä–∞–≤–Ω–µ–Ω–∏–µ/–≠—Ç–∞–ª–æ–Ω"
compared_folder = "–±–∞—Ç—á–∏–Ω–≥-—Ç–µ—Å—Ç/–°—Ä–∞–≤–Ω–µ–Ω–∏–µ/–ü—Ä–æ—Ç–∏–≤–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–µ"
images_folder = "images"  # –ü–∞–ø–∫–∞ —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏ –∑–∞—è–≤–æ–∫
DB_PATH = "documents.db"

def extract_number(filename):
    match = re.match(r"(\d+)", filename)
    return int(match.group(1)) if match else float('inf')

def show_application_card(app_data):
    st.markdown("---")
    st.header(f"–ö–∞—Ä—Ç–æ—á–∫–∞ –∑–∞—è–≤–∫–∏ {app_data['application_number']}")
    st.write(f"**–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏:** {app_data['application_number']}")
    st.write(f"**–î–∞—Ç–∞ –ø–æ–¥–∞—á–∏:** {app_data['application_date']}")
    st.write(f"**–ü—É–±–ª–∏–∫–∞—Ü–∏—è:** {app_data['publication']}")
    st.write(f"**–ù–æ–º–µ—Ä –±—é–ª–ª–µ—Ç–µ–Ω—è:** {app_data['bulletin_number']}")
    st.write(f"**–ó–∞—è–≤–∏—Ç–µ–ª—å:** {app_data['applicant']}")
    st.write(f"**–ê–¥—Ä–µ—Å:** {app_data['correspondence_address']}")
    st.write(f"**–ö–ª–∞—Å—Å—ã –ú–ö–¢–£:** {app_data['classes']}")
    if st.button("–ó–∞–∫—Ä—ã—Ç—å –∫–∞—Ä—Ç–æ—á–∫—É"):
        st.session_state.selected_app = None
        st.experimental_rerun()

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CLIP ===
device = "cuda" if torch.cuda.is_available() else "cpu"
model_name = "ViT-B/16"
model, preprocess = clip.load(model_name, device=device)
BATCH_SIZE = 16

def enhance_image(image):
    image = image.resize((512, 512), Image.BICUBIC)
    image = ImageEnhance.Contrast(image).enhance(1.5)
    image = ImageEnhance.Sharpness(image).enhance(1.3)
    return image

st.title("üîç –õ–æ–≥–æ—Ç–∏–ø—ã –∏ –∑–∞—è–≤–∫–∏")

tabs = st.tabs(["–í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ", "–ü–æ–∏—Å–∫ –ø–æ –∑–∞—è–≤–∫–∞–º", "–ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É (–ò–ò)"])

# --- –ü–µ—Ä–≤–∞—è –≤–∫–ª–∞–¥–∫–∞: –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ---
with tabs[0]:
    etalon_files = [f for f in os.listdir(etalon_folder) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
    etalon_files.sort(key=extract_number)

    selected_etalon = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —ç—Ç–∞–ª–æ–Ω", etalon_files)

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("""
        SELECT compared, similarity
        FROM clip_similarity
        WHERE etalon = ?
        ORDER BY similarity DESC
        LIMIT 30
    """, (selected_etalon,))
    top_matches = cursor.fetchall()
    conn.close()

    import pandas as pd
    df = pd.DataFrame(top_matches, columns=["–§–∞–π–ª", "–°—Ö–æ–¥—Å—Ç–≤–æ"])
    df.insert(0, "Top", [f"Top {i+1}" for i in range(len(df))])
    select_options = [f"{row.Top} ‚Äî {row.–§–∞–π–ª}" for _, row in df.iterrows()]
    selected_option = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ª–æ–≥–æ—Ç–∏–ø –∏–∑ —Å–ø–∏—Å–∫–∞", select_options)
    selected_file = selected_option.split(" ‚Äî ", 1)[1]

    col1, col2 = st.columns(2)
    with col1:
        etalon_path = os.path.join(etalon_folder, selected_etalon)
        st.subheader("üéØ –≠—Ç–∞–ª–æ–Ω")
        st.image(etalon_path, caption=selected_etalon, width=300)
    with col2:
        if selected_file:
            image_path = os.path.join(compared_folder, selected_file)
            try:
                image = Image.open(image_path)
                st.subheader("ü§ù –ü–æ—Ö–æ–∂–∏–π –ª–æ–≥–æ—Ç–∏–ø")
                st.image(image, caption=selected_file, width=300)
            except Exception:
                st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")

    st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ –ø–æ—Ö–æ–∂–∏—Ö –ª–æ–≥–æ—Ç–∏–ø–æ–≤ (—Ç–æ–ø 5)")
    st.dataframe(df.head(5), use_container_width=True)

# --- –í—Ç–æ—Ä–∞—è –≤–∫–ª–∞–¥–∫–∞: –ü–æ–∏—Å–∫ –ø–æ –∑–∞—è–≤–∫–∞–º ---
with tabs[1]:
    st.title("üîé –ü–æ–∏—Å–∫ –ø–æ –∑–∞—è–≤–∫–∞–º –Ω–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤")

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute("SELECT classes FROM documents_pdf")
    all_classes_raw = [row[0] for row in cursor.fetchall()]
    unique_classes = set()
    for cl_str in all_classes_raw:
        unique_classes.update([c.strip() for c in cl_str.split(",") if c.strip()])
    unique_classes = sorted(unique_classes)

    cursor.execute("SELECT MIN(application_date), MAX(application_date) FROM documents_pdf")
    min_date_str, max_date_str = cursor.fetchone()

    def str_to_date(s):
        try:
            return datetime.strptime(s, "%d.%m.%Y").date()
        except Exception:
            return None

    min_date = str_to_date(min_date_str) or date.today()
    max_date = str_to_date(max_date_str) or date.today()

    selected_dates = st.date_input(
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–∫–∏ (–¥–∏–∞–ø–∞–∑–æ–Ω)",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )

    selected_classes = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –∫–ª–∞—Å—Å—ã –ú–ö–¢–£", unique_classes)

    query = "SELECT application_number, application_date, publication, bulletin_number, applicant, correspondence_address, classes FROM documents_pdf WHERE 1=1"
    params = []

    if selected_dates and len(selected_dates) == 2:
        start_date, end_date = selected_dates
        start_str = start_date.strftime("%d.%m.%Y")
        end_str = end_date.strftime("%d.%m.%Y")
        query += " AND (application_date BETWEEN ? AND ?)"
        params.extend([start_str, end_str])

    if selected_classes:
        like_clauses = []
        for cl in selected_classes:
            like_clauses.append("classes LIKE ?")
            params.append(f"%{cl}%")
        query += " AND (" + " OR ".join(like_clauses) + ")"

    query += " ORDER BY application_date DESC LIMIT 100"

    cursor.execute(query, params)
    rows = cursor.fetchall()
    conn.close()

    all_apps = {row[0]: {
        'application_number': row[0],
        'application_date': row[1],
        'publication': row[2],
        'bulletin_number': row[3],
        'applicant': row[4],
        'correspondence_address': row[5],
        'classes': row[6],
    } for row in rows}

    st.header(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∑–∞—è–≤–æ–∫ ({len(rows)} –∏–∑ –º–∞–∫—Å–∏–º—É–º 100)")

    if not rows:
        st.info("–ü–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –∑–∞—è–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    else:
        cols_per_row = 3
        for i in range(0, len(rows), cols_per_row):
            cols = st.columns(cols_per_row)
            for col, row in zip(cols, rows[i:i+cols_per_row]):
                app_num = row[0]
                img_path = None
                for ext in ['jpg', 'png']:
                    path = os.path.join(images_folder, f"{app_num}.{ext}")
                    if os.path.exists(path):
                        img_path = path
                        break
                with col:
                    if img_path:
                        if st.button(app_num, key=f"btn_{app_num}"):
                            show_application_card(all_apps[app_num])
                        st.image(img_path, use_container_width=True)
                    else:
                        st.write(f"üñº –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è {app_num}")
                        if st.button(app_num, key=f"btn_{app_num}"):
                            show_application_card(all_apps[app_num])

# --- –¢—Ä–µ—Ç—å—è –≤–∫–ª–∞–¥–∫–∞: –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É (–ò–ò) ---
with tabs[2]:
    st.header("–ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É (–ò–ò)")
    st.write("–ò–ò –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –ø–æ –≤—Å–µ–º —Ç–æ–≤–∞—Ä–Ω—ã–º –∑–Ω–∞–∫–∞–º –≤ –±–∞–∑–µ")

    text_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫)", height=100)

    if st.button("üîç –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–∏—Å–∫"):
        if not text_input.strip():
            st.warning("–í–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å.")
        else:
            folder = compared_folder

            text_queries = [line.strip() for line in text_input.split("\n") if line.strip()]
            text_tokens = clip.tokenize(text_queries).to(device)
            with torch.no_grad():
                text_features = model.encode_text(text_tokens)
                text_features = text_features.mean(dim=0, keepdim=True)
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                text_features = text_features.cpu()

            image_files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]
            total_images = len(image_files)
            results = []

            progress_bar = st.progress(0, text=f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ 0 –∏–∑ {total_images}")

            for i in range(0, total_images, BATCH_SIZE):
                batch_files = image_files[i:i + BATCH_SIZE]
                batch_images = []
                valid_files = []

                for fname in batch_files:
                    try:
                        image_path = os.path.join(folder, fname)
                        image = Image.open(image_path).convert("RGB")
                        image = enhance_image(image)
                        image_tensor = preprocess(image)
                        batch_images.append(image_tensor)
                        valid_files.append(fname)
                    except Exception as e:
                        st.warning(f"–û—à–∏–±–∫–∞ —Å —Ñ–∞–π–ª–æ–º {fname}: {e}")

                if batch_images:
                    batch_tensor = torch.stack(batch_images).to(device)
                    with torch.no_grad():
                        image_features = model.encode_image(batch_tensor)
                        image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                        image_features = image_features.cpu()

                    similarities = (image_features @ text_features.T).squeeze(1)

                    for fname, sim in zip(valid_files, similarities):
                        results.append((fname, sim.item()))

                done = min(i + BATCH_SIZE, total_images)
                progress_bar.progress(done / total_images, text=f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {done} –∏–∑ {total_images}")

            results.sort(key=lambda x: x[1], reverse=True)
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (—Ç–æ–ø-5):")

            for fname, score in results[:5]:
                img_path = os.path.join(folder, fname)
                st.image(img_path, caption=f"{fname} ‚Äî –°—Ö–æ–¥—Å—Ç–≤–æ: {score:.4f}", use_container_width=True)
